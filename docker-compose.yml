services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: verixai-postgres
    environment:
      POSTGRES_USER: verixai
      POSTGRES_PASSWORD: verixai_password
      POSTGRES_DB: verixai_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - verixai-network
    healthcheck:
      test: ["CMD-SHELL", "echo hi"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ChromaDB Vector Database
  chromadb:
    image: chromadb/chroma:latest
    container_name: verixai-chromadb
    volumes:
      - chroma_data:/chroma/chroma
    ports:
      - "8001:8000"
    networks:
      - verixai-network
    environment:
      IS_PERSISTENT: TRUE
      ANONYMIZED_TELEMETRY: FALSE

  # # Ollama Service (for local LLM)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: verixai-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - verixai-network
  #   environment:
  #     OLLAMA_KEEP_ALIVE: "5m"
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
  #   command: serve

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: verixai-backend
    environment:
      DATABASE_URL: postgresql+asyncpg://verixai:verixai_password@postgres:5432/verixai_db
      CHROMA_HOST: chromadb
      CHROMA_PORT: 8000
      # LLM Provider Configuration
      LLM_PROVIDER: ${LLM_PROVIDER:-ollama}
      EMBEDDING_PROVIDER: ${EMBEDDING_PROVIDER:-ollama}
      # Ollama Configuration
      # OLLAMA_BASE_URL: http://ollama:11434
      # OLLAMA_CHAT_MODEL: ${OLLAMA_CHAT_MODEL:-llama3.2}
      # OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}

      OLLAMA_BASE_URL: http://192.168.0.124:11434
      OLLAMA_CHAT_MODEL: ${OLLAMA_CHAT_MODEL:-deepseek-r1:14b}
      OLLAMA_EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL:-nomic-embed-text}

      # OpenAI Configuration (Optional)
      # OPENAI_API_KEY: ${OPENAI_API_KEY}
      # OPENAI_CHAT_MODEL: ${OPENAI_CHAT_MODEL:-gpt-4-turbo-preview}
      # OPENAI_EMBEDDING_MODEL: ${OPENAI_EMBEDDING_MODEL:-text-embedding-3-small}
      # Claude Configuration (Optional)
      # CLAUDE_API_KEY: ${CLAUDE_API_KEY}
      # CLAUDE_CHAT_MODEL: ${CLAUDE_CHAT_MODEL:-claude-3-opus-20240229}
      SECRET_KEY: ${SECRET_KEY:-change-me-in-production}
    volumes:
      - ./backend:/app
      - ./uploads:/app/uploads
      - ./datasets:/app/datasets
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      chromadb:
        condition: service_started
      # ollama:
      #   condition: service_started
    networks:
      - verixai-network

  # Frontend React App with Vite
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: verixai-frontend
    environment:
      VITE_API_URL: http://localhost:8000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - verixai-network

networks:
  verixai-network:
    driver: bridge

volumes:
  postgres_data:
  chroma_data:
  # ollama_data: